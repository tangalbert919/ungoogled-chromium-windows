# Convert Google's build scripts to Python 3, as Python 2 support was dropped.

--- a/build/vs_toolchain.py
+++ b/build/vs_toolchain.py
@@ -3,7 +3,7 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.

-from __future__ import print_function
+

 import collections
 import glob
@@ -114,12 +114,12 @@
     contents of the registry key's value, or None on failure.  Throws
     ImportError if _winreg is unavailable.
   """
-  import _winreg
+  import winreg
   try:
     root, subkey = key.split('\\', 1)
     assert root == 'HKLM'  # Only need HKLM for now.
-    with _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, subkey) as hkey:
-      return _winreg.QueryValueEx(hkey, value)[0]
+    with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, subkey) as hkey:
+      return winreg.QueryValueEx(hkey, value)[0]
   except WindowsError:
     return None

@@ -139,7 +139,7 @@
   if env_version:
     return env_version

-  supported_versions = MSVS_VERSIONS.keys()
+  supported_versions = list(MSVS_VERSIONS.keys())

   # VS installed in depot_tools for Googlers
   if bool(int(os.environ.get('DEPOT_TOOLS_WIN_TOOLCHAIN', '1'))):
@@ -147,7 +147,7 @@

   # VS installed in system for external developers
   supported_versions_str = ', '.join('{} ({})'.format(v,k)
-      for k,v in MSVS_VERSIONS.items())
+      for k,v in list(MSVS_VERSIONS.items()))
   available_versions = []
   for version in supported_versions:
     for path in (
--- a/build/toolchain/win/setup_toolchain.py
+++ b/build/toolchain/win/setup_toolchain.py
@@ -10,7 +10,7 @@
 # win tool. The script assumes that the root build directory is the current dir
 # and the files will be written to the current directory.

-from __future__ import print_function
+

 import errno
 import json
@@ -167,7 +167,7 @@
   CreateProcess documentation for more details."""
   block = ''
   nul = '\0'
-  for key, value in envvar_dict.items():
+  for key, value in list(envvar_dict.items()):
     block += key + '=' + value + nul
   block += nul
   return block
@@ -256,7 +256,7 @@
       lib = [p.replace('"', r'\"') for p in env['LIB'].split(';') if p]
       # Make lib path relative to builddir when cwd and sdk in same drive.
       try:
-        lib = map(os.path.relpath, lib)
+        lib = list(map(os.path.relpath, lib))
       except ValueError:
         pass

--- a/tools/metrics/histograms/generate_expired_histograms_array.py
+++ b/tools/metrics/histograms/generate_expired_histograms_array.py
@@ -71,7 +71,7 @@
     Error if there is an expiry date that doesn't match expected format.
   """
   expired_histograms_names = []
-  for name, content in histograms.items():
+  for name, content in list(histograms.items()):
     if "obsolete" in content or "expires_after" not in content:
       continue
     expiry_str = content["expires_after"]
--- a/tools/metrics/histograms/extract_histograms.py
+++ b/tools/metrics/histograms/extract_histograms.py
@@ -53,7 +53,7 @@

 """

-import HTMLParser
+import html.parser
 import bisect
 import copy
 import datetime
@@ -108,7 +108,7 @@

   # Unescape using default ASCII encoding. Unescapes any HTML escaped character
   # like &quot; etc.
-  return HTMLParser.HTMLParser().unescape(singleline_value)
+  return html.parser.HTMLParser().unescape(singleline_value)


 def _NormalizeAllAttributeValues(node):
@@ -121,7 +121,7 @@
     The normalized minidom node.
   """
   if node.nodeType == xml.dom.minidom.Node.ELEMENT_NODE:
-    for a in node.attributes.keys():
+    for a in list(node.attributes.keys()):
       node.attributes[a].value = _NormalizeString(node.attributes[a].value)

   for c in node.childNodes:
--- a/base/win/embedded_i18n/create_string_rc.py
+++ b/base/win/embedded_i18n/create_string_rc.py
@@ -58,7 +58,7 @@
 # and IDS_L10N_OFFSET_* for the language we are interested in.
 #

-from __future__ import print_function
+

 import argparse
 import glob
@@ -280,7 +280,7 @@
   def __AddModeSpecificStringIds(self):
     """Adds the mode-specific strings for all of the current brand's install
     modes to self.string_id_set."""
-    for string_id, brands in self.mode_specific_strings.items():
+    for string_id, brands in list(self.mode_specific_strings.items()):
       brand_strings = brands.get(self.brand)
       if not brand_strings:
         raise RuntimeError(
@@ -358,7 +358,7 @@
     # Manually put the source strings as en-US in the list of translated
     # strings.
     translated_strings = []
-    for string_id, message_text in source_strings.items():
+    for string_id, message_text in list(source_strings.items()):
       translated_strings.append(self.__TranslationData(string_id,
                                                        'EN_US',
                                                        message_text))
@@ -368,7 +368,7 @@
     # message text; hence the message id is mapped to a list of string ids
     # instead of a single value.
     translation_ids = {}
-    for (string_id, message_text) in source_strings.items():
+    for (string_id, message_text) in list(source_strings.items()):
       message_id = tclib.GenerateMessageId(message_text)
       translation_ids.setdefault(message_id, []).append(string_id);

@@ -383,7 +383,7 @@
       if not xtb_filename in source_xtb_files:
         extra_xtb_files.append(xtb_filename)
       sax_parser.parse(xtb_filename)
-      for string_id, message_text in source_strings.items():
+      for string_id, message_text in list(source_strings.items()):
         translated_string = xtb_handler.translations.get(string_id,
                                                          message_text)
         translated_strings.append(self.__TranslationData(string_id,
@@ -407,13 +407,13 @@
     """Writes a resource file with the strings provided in |translated_strings|.
     """
     HEADER_TEXT = (
-      u'#include "%s"\n\n'
-      u'STRINGTABLE\n'
-      u'BEGIN\n'
+      '#include "%s"\n\n'
+      'STRINGTABLE\n'
+      'BEGIN\n'
       ) % os.path.basename(self.header_file)

     FOOTER_TEXT = (
-      u'END\n'
+      'END\n'
     )

     with io.open(self.rc_file,
@@ -426,7 +426,7 @@
         escaped_text = (translation.translation.replace('"', '""')
                        .replace('\t', '\\t')
                        .replace('\n', '\\n'))
-        outfile.write(u'  %s "%s"\n' %
+        outfile.write('  %s "%s"\n' %
                       (translation.resource_id_str + '_' + translation.language,
                        escaped_text))
       outfile.write(FOOTER_TEXT)
@@ -463,7 +463,7 @@
       resource_id += 1

     # Handle mode-specific strings.
-    for string_id, brands in self.mode_specific_strings.items():
+    for string_id, brands in list(self.mode_specific_strings.items()):
       # Populate the DO_MODE_STRINGS macro.
       brand_strings = brands.get(self.brand)
       if not brand_strings:
@@ -575,7 +575,7 @@
       parser.error('A brand was specified (' + brand + ') but no mode '
         'specific strings were given.')
     valid_brands = [b for b in
-      mode_specific_strings.itervalues().next().iterkeys()]
+      next(iter(mode_specific_strings.values()))]
     if not brand in valid_brands:
       parser.error('A brand was specified (' + brand + ') but it is not '
         'a valid brand [' + ', '.join(valid_brands) + '].')
@@ -590,7 +590,7 @@
     parser.error('Mismatch in number of grd files ({}) and xtb relative '
                  'paths ({})'.format(len(grd_files), len(xtb_relative_paths)))

-  inputs = zip(grd_files, xtb_relative_paths)
+  inputs = list(zip(grd_files, xtb_relative_paths))

   StringRcMaker(inputs, args.expected_xtb_input_files, args.header_file,
     args.rc_file,  brand, args.first_resource_id, string_ids_to_extract,
--- a/mojo/public/tools/bindings/mojom_bindings_generator.py
+++ b/mojo/public/tools/bindings/mojom_bindings_generator.py
@@ -5,12 +5,12 @@

 """The frontend for the Mojo bindings system."""

-from __future__ import print_function
+

 import argparse

 try:
-  import cPickle as pickle
+  import pickle as pickle
 except ImportError:
   import pickle

@@ -164,7 +164,7 @@
     for filename in typemaps:
       with open(filename) as f:
         typemaps = json.loads("".join(filter(no_comments, f.readlines())))
-        for language, typemap in typemaps.items():
+        for language, typemap in list(typemaps.items()):
           language_map = self._typemap.get(language, {})
           language_map.update(typemap)
           self._typemap[language] = language_map
@@ -208,7 +208,7 @@

     if self._should_generate(rel_filename.path):
       AddComputedData(module)
-      for language, generator_module in generator_modules.items():
+      for language, generator_module in list(generator_modules.items()):
         generator = generator_module.Generator(
             module, args.output_dir, typemap=self._typemap.get(language, {}),
             variant=args.variant, bytecode_path=args.bytecode_path,
@@ -330,7 +330,7 @@


 def _Precompile(args, _):
-  generator_modules = LoadGenerators(",".join(_BUILTIN_GENERATORS.keys()))
+  generator_modules = LoadGenerators(",".join(list(_BUILTIN_GENERATORS.keys())))

   template_expander.PrecompileTemplates(generator_modules, args.output_dir)
   return 0
